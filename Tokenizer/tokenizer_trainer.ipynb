{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab3bcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers, decoders\n",
    "from tokenizers.processors import TemplateProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa02d31",
   "metadata": {},
   "source": [
    "# 1. Tokenizer Model Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa65ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(models.BPE(unk_token=\"<unk>\"))\n",
    "\n",
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "\n",
    "tokenizer.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d101b7a",
   "metadata": {},
   "source": [
    "# 2. Tokenizer Ayarlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c369e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\n",
    "    \"<pad>\",         # Padding token\n",
    "    \"<unk>\",         # Bilinmeyen token\n",
    "    \"<s>\",           # BOS (beginning of sentence)\n",
    "    \"</s>\",          # EOS (end of sentence)\n",
    "    \"<|bos|>\",       # GPT-style BOS (CLM için)\n",
    "    \"<|eos|>\",       # GPT-style EOS (CLM için)\n",
    "    \"<|endoftext|>\", # OpenAI tarzı metin sonu işareti (opsiyonel ama faydalı)\n",
    "    \"<|user|>\",      # Kullanıcı prompt başlangıcı\n",
    "    \"<|assistant|>\", # Model cevabı başlangıcı\n",
    "    \"<|system|>\",    # Sistem talimatları (instruct formatları için)\n",
    "    \"<|sep|>\"        # Prompt–response ayracı (isteğe bağlı)\n",
    "]\n",
    "\n",
    "\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=50_000, \n",
    "    limit_alphabet=2000, \n",
    "    max_token_length=100, \n",
    "    special_tokens=special_tokens, \n",
    "    show_progress=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f45b3f",
   "metadata": {},
   "source": [
    "# 3. Tokenizer Eğitimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b1fc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.train(files=[\"./BPE_TokenizerTexts.txt\"], trainer=trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2532bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.post_processor = TemplateProcessing(\n",
    "    single=\"<s> $A </s>\",\n",
    "    pair=\"<s> $A </s> </s> $B </s>\",\n",
    "    special_tokens=[\n",
    "        (\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        (\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598da038",
   "metadata": {},
   "source": [
    "# 4. Tokenizer Kayıt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f93921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "✅ BPE Tokenizer eğitimi tamamlandı.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.save(\"tokenizer.json\")\n",
    "print(\"✅ BPE Tokenizer eğitimi tamamlandı.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2efab8",
   "metadata": {},
   "source": [
    "# 5. Tokenizer Huggingface Formatına Çevir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec87aabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ HuggingFace uyumlu tokenizer kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "hf_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_file=\"./tokenizer.json\",\n",
    "    pad_token=\"<pad>\",\n",
    "    unk_token=\"<unk>\",\n",
    "    bos_token=\"<|bos|>\",\n",
    "    eos_token=\"<|eos|>\",\n",
    "    additional_special_tokens=[\n",
    "        \"<|user|>\", \"<|assistant|>\", \"<|system|>\", \"<|sep|>\", \"<|endoftext|>\", # \"<|bos|>\", \"<|eos|>\", \n",
    "    ]\n",
    ")\n",
    "\n",
    "hf_tokenizer.save_pretrained(\"Crispy Tokenizer\")\n",
    "print(\"✅ HuggingFace uyumlu tokenizer kaydedildi.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
